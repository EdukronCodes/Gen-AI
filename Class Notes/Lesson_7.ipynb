{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CPbsBNDbVOH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Module 8: Agents and Tool Use\n",
        "\n",
        "### 1. Understanding LangChain Agents\n",
        "\n",
        "LangChain Agents are a powerful concept that elevates Large Language Models (LLMs) from mere text generators or simple Q&A systems into dynamic problem-solvers. Think of an LLM as a brilliant but purely theoretical brain; it knows a lot but can't directly interact with the world or perform specific calculations beyond its training. Agents act as the conductor, giving this brain access to \"hands and senses\" â€“ these are the tools. The agent uses the LLM's reasoning capabilities to decide which tool to use, how to use it, and how to interpret the tool's output to achieve a given objective. This creates a loop where the agent thinks, acts (using a tool), observes the result, and thinks again until the task is complete or it decides it cannot proceed further.\n",
        "\n",
        "The core idea is to combine the LLM's language understanding and reasoning with the concrete capabilities of external tools. For example, an LLM alone can't tell you the current weather, but an agent equipped with a weather API tool can. The agent understands the user's request for weather, decides the weather tool is appropriate, formulates the correct query for the tool (e.g., \"weather in London\"), gets the structured data back from the API, and then uses the LLM to present this information in a natural, human-readable way. This makes agents incredibly versatile for tasks requiring up-to-date information, calculations, or interactions with other systems.\n",
        "\n",
        "**Detailed Notes: Understanding LangChain Agents**\n",
        "\n",
        "1.  **LLM as the Core Brain:** At the heart of every LangChain agent lies a Large Language Model (LLM), which provides the reasoning and decision-making capabilities.\n",
        "    The LLM analyzes the user's request and its internal state to figure out the best course of action.\n",
        "2.  **Tools as External Capabilities:** Agents are equipped with a set of \"tools\" that allow them to perform actions beyond the LLM's inherent abilities, like searching or calculating.\n",
        "    Imagine a skilled craftsman (the LLM) who is given a toolbox (the tools) to build something complex (solve the user's query).\n",
        "3.  **Decision-Making Loop:** Agents operate in a loop where the LLM decides what action to take (which tool to use and with what input).\n",
        "    This is similar to how a human might approach a problem: think about the next step, perform an action, observe the result, and then think again.\n",
        "4.  **Goal-Oriented Operation:** Agents are designed to achieve a specific goal or answer a complex question posed by the user.\n",
        "    They will continue to use tools and reason until they believe the goal is met or determine it's impossible with available resources.\n",
        "5.  **Bridging LLM Limitations:** Agents help overcome LLM limitations, such as knowledge cutoffs (by using search tools) or inability to perform precise math (by using a calculator tool).\n",
        "    If an LLM was trained up to 2021, an agent with a search tool can still answer questions about events in 2023.\n",
        "6.  **Structured Interaction:** Agents need tools to have well-defined inputs and outputs so the LLM can reliably interact with them.\n",
        "    The LLM must be able to formulate a query for a tool in a way the tool understands, and interpret its response.\n",
        "7.  **Prompt Engineering is Key:** The effectiveness of an agent heavily relies on the \"agent prompt\" that instructs the LLM on how to reason and use tools.\n",
        "    This prompt often includes examples of thought processes and tool usage to guide the LLM.\n",
        "8.  **Versatility and Application:** Agents can be used for a wide range of tasks, from simple information retrieval to complex multi-step problem-solving.\n",
        "    Examples include customer service bots, research assistants, or even simple coding assistants.\n",
        "9.  **State Management (Implicit/Explicit):** Agents often need to maintain some form of state or memory of previous steps and observations to make informed decisions.\n",
        "    This \"scratchpad\" of thoughts and actions helps the agent track progress and avoid repeating mistakes.\n",
        "10. **Increased Complexity and Cost:** While powerful, agents can be more complex to set up and debug than direct LLM calls, and each tool use or LLM reasoning step incurs costs.\n",
        "    However, the ability to solve more sophisticated problems often justifies this added complexity and operational expense.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Tools: Search, Math, Python REPL, API access\n",
        "\n",
        "Tools are the essential extensions that grant LangChain agents their power to interact with the world and perform specialized tasks. Without tools, an LLM is confined to its pre-trained knowledge and linguistic abilities. A \"Search\" tool, for instance, connects the agent to real-time information from the internet, overcoming the LLM's knowledge cutoff. Think of it as giving the agent a library card and internet access. A \"Math\" tool (often a calculator or a symbolic math engine) allows the agent to perform precise numerical calculations, something LLMs can struggle with, especially for complex arithmetic. This is like giving the agent a calculator for tasks requiring accuracy.\n",
        "\n",
        "The \"Python REPL\" (Read-Eval-Print Loop) tool is particularly powerful, as it allows the agent to write and execute Python code. This opens up a vast range of possibilities, from data manipulation and complex algorithmic tasks to interacting with local files, essentially giving the agent a mini-programming environment. Finally, \"API access\" tools allow agents to interact with any external service that exposes an Application Programming Interface. This could be anything from a weather service, a stock market data provider, a company's internal database, or even another AI service, effectively making the agent a universal connector.\n",
        "\n",
        "**Detailed Notes: Tools: Search, Math, Python REPL, API access**\n",
        "\n",
        "1.  **Search Tool (e.g., Google Search, DuckDuckGo, Tavily):** Provides the agent with the ability to query search engines for up-to-date information or facts not present in the LLM's training data.\n",
        "    Example: An agent asked \"What was the headline news yesterday?\" would use a search tool to find current events.\n",
        "2.  **Math Tool (e.g., `llm-math`):** Enables the agent to perform precise mathematical calculations, leveraging a calculator or symbolic math engine.\n",
        "    This is crucial because LLMs can sometimes \"hallucinate\" or make errors in arithmetic, especially for multi-step calculations.\n",
        "3.  **Python REPL Tool:** Allows the agent to execute Python code in a sandboxed environment, performing computations, data processing, or even simple scripting.\n",
        "    An agent could use this to, for example, sort a list of numbers or calculate the standard deviation of a dataset it received from another tool.\n",
        "4.  **API Access Tools (General):** These are custom or pre-built tools that allow the agent to interact with specific third-party APIs.\n",
        "    This could be an API for booking flights, checking stock prices, or accessing a company's internal knowledge base.\n",
        "5.  **Tool Description is Crucial:** For an agent to effectively use a tool, the tool must have a clear and concise description explaining what it does and what kind of input it expects.\n",
        "    The LLM uses these descriptions to decide which tool is most appropriate for a given sub-task.\n",
        "6.  **Structured Input/Output:** Tools are designed to accept structured input (often a string or a JSON object) and return a structured output.\n",
        "    This predictability is essential for the LLM to reliably call the tool and interpret its results.\n",
        "7.  **Overcoming LLM Hallucinations:** Tools provide factual grounding. If an LLM is unsure about a calculation or a recent fact, it can defer to a specialized tool.\n",
        "    Using a math tool for \"what is 17.5 * 23.9?\" is much more reliable than asking the LLM to compute it directly.\n",
        "8.  **Security Considerations:** Tools, especially the Python REPL or those making external API calls, introduce security considerations.\n",
        "    It's vital to ensure that tools cannot be exploited to perform malicious actions or access sensitive data inappropriately.\n",
        "9.  **Extensibility:** LangChain provides a framework for easily creating and integrating custom tools, tailoring the agent's capabilities to specific needs.\n",
        "    If you have a proprietary database, you can build a custom API tool for the agent to query it.\n",
        "10. **Tool Chaining:** Agents can use multiple tools in sequence, where the output of one tool might become part of the input for another.\n",
        "    For instance, an agent might search for a company's stock ticker (Search tool) and then use that ticker to get its current price (API access tool).\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Custom tool creation\n",
        "\n",
        "Creating custom tools in LangChain is essential when the out-of-the-box tools don't cater to your specific needs or when you want an agent to interact with proprietary systems or perform unique actions. The process involves defining a Python function (or coroutine for asynchronous operations) that encapsulates the desired logic. This function will take an input (usually a string) and return an output (also usually a string, which the LLM will then process). LangChain provides a `Tool` class that wraps this function, requiring you to specify a `name` for the tool (how the agent will refer to it) and, critically, a `description`.\n",
        "\n",
        "The `description` is paramount because the LLM uses it to understand what the tool does and when to use it. A well-crafted description clearly outlines the tool's purpose, its expected input format, and what it returns. For example, a custom tool to fetch user preferences from a database might have a description like: \"Useful for when you need to find the stored preferences for a specific user. Input should be the user's ID.\" This allows the agent's reasoning mechanism to correctly identify and utilize your custom functionality, effectively extending its capabilities to virtually any task you can program.\n",
        "\n",
        "**Detailed Notes: Custom tool creation**\n",
        "\n",
        "1.  **Define Core Logic as a Function:** The first step is to write a Python function (or an async coroutine) that performs the specific action your tool needs to do.\n",
        "    This function will take an input (typically a string query from the LLM) and return a string result.\n",
        "2.  **Import `Tool` from `langchain.tools`:** LangChain provides a `Tool` class (or `BaseTool` for more advanced scenarios) to wrap your custom function.\n",
        "    This class standardizes how tools are defined and integrated into the agent framework.\n",
        "3.  **Provide a `name`:** The `name` attribute is a short, descriptive identifier that the LLM will use in its \"Action\" step to specify which tool to run.\n",
        "    For example, `get_user_email` or `internal_document_search`.\n",
        "4.  **Craft a Clear `description`:** The `description` is crucial. It's a natural language explanation of what the tool does, what input it expects, and what it returns.\n",
        "    The LLM relies heavily on this description to decide *when* and *how* to use the tool. E.g., \"Useful for finding a user's email address. Input should be their username.\"\n",
        "5.  **Instantiate the `Tool` Class:** You create an instance of the `Tool` class, passing your function to the `func` argument, and providing the `name` and `description`.\n",
        "    `my_custom_tool = Tool(name=\"user_lookup\", description=\"Finds user details. Input: user ID.\", func=my_lookup_function)`\n",
        "6.  **Input Schema (Optional but Recommended):** For more complex tools, you can define an input schema using Pydantic models via `args_schema`.\n",
        "    This helps with input validation and can provide better guidance to the LLM on how to structure the tool's input.\n",
        "7.  **Error Handling within the Tool:** Your custom function should handle potential errors gracefully and return informative messages.\n",
        "    If a database lookup fails, the tool should return \"User ID not found\" rather than crashing, so the agent can react.\n",
        "8.  **Keep Tools Focused:** It's generally better to create multiple, smaller, specialized tools rather than one monolithic tool that tries to do too much.\n",
        "    This makes it easier for the LLM to select the right tool for a specific sub-task.\n",
        "9.  **Testing the Tool Independently:** Before integrating a custom tool into an agent, test its underlying function thoroughly with various inputs.\n",
        "    Ensure it behaves as expected and handles edge cases correctly to avoid confusing the agent.\n",
        "10. **Iterative Refinement:** The description of your tool might need refinement based on how the agent actually uses it (or fails to use it).\n",
        "    Observing the agent's thought process can help you tweak the description for better tool selection.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. Multi-step reasoning with ReAct (Reasoning + Acting)\n",
        "\n",
        "ReAct, which stands for \"Reasoning and Acting,\" is a powerful prompting paradigm that enables LLMs to perform complex, multi-step tasks by explicitly interweaving thought processes with actions. Instead of trying to generate a final answer in one go, an agent using the ReAct framework breaks the problem down. It first \"Thinks\" about the problem, forms a plan or identifies a sub-goal, and decides what \"Action\" to take (usually invoking a tool). After the action is performed, it receives an \"Observation\" (the result from the tool). This Thought-Action-Observation cycle repeats, allowing the agent to build upon previous results, correct mistakes, and navigate towards the final solution.\n",
        "\n",
        "Imagine a detective solving a crime. They don't just guess the culprit. They think (\"The alibi seems weak\"), take an action (\"Interview witness B\"), get an observation (\"Witness B confirms suspect was elsewhere\"), and then think again based on this new information. ReAct agents do something similar. For example, to answer \"What is the current population of the capital of France, and what is its main tourist attraction?\", the agent might: Think (I need to find the capital of France), Action (Search: \"capital of France\"), Observation (Result: Paris). Think (Now I need population of Paris), Action (Search: \"population of Paris\"), Observation (Result: ~2.1 million). Think (Now I need main tourist attraction of Paris), Action (Search: \"main tourist attraction Paris\"), Observation (Result: Eiffel Tower). Finally, it combines these pieces to form the answer. This iterative process allows for dynamic problem-solving and the handling of queries that require information gathering or computation in stages.\n",
        "\n",
        "**Detailed Notes: Multi-step reasoning with ReAct (Reasoning + Acting)**\n",
        "\n",
        "1.  **Core Cycle: Thought, Action, Observation:** ReAct operates on an iterative loop where the LLM generates a thought, decides on an action, and then receives an observation.\n",
        "    This mimics a human's conscious problem-solving process: strategize, execute, evaluate.\n",
        "2.  **Thought:** In this step, the LLM explicitly reasons about the current state of the problem, what information is still needed, and what the next logical step should be.\n",
        "    Example thought: \"I need to find the birth date of the actor. I should use the search tool.\"\n",
        "3.  **Action:** Based on the thought, the LLM decides to either use a specific tool with a particular input, or, if it believes it has enough information, to provide the final answer.\n",
        "    Example action: `Search(\"birth date of Tom Hanks\")` or `Final Answer: The answer is X.`\n",
        "4.  **Observation:** This is the result returned after an action is performed (e.g., the output from a tool).\n",
        "    Example observation: \"Tom Hanks was born on July 9, 1956.\"\n",
        "5.  **Iterative Refinement:** The agent uses the observation from the previous step to inform its next thought, allowing it to adjust its plan and progressively solve the problem.\n",
        "    If a search yields no results, the next thought might be to try a different search query or a different tool.\n",
        "6.  **Prompting for ReAct:** The agent's main prompt is structured to encourage this Thought-Action-Observation pattern, often including few-shot examples.\n",
        "    The prompt guides the LLM to \"think out loud\" and follow the ReAct format.\n",
        "7.  **Handling Complex Queries:** ReAct excels at tasks that cannot be answered in a single step and require information gathering, intermediate calculations, or chained operations.\n",
        "    For instance, \"Who was the monarch of England when the composer of 'The Four Seasons' was born?\" requires multiple lookups.\n",
        "8.  **Increased Transparency:** The explicit thought process generated by the ReAct agent provides insight into *how* it arrived at an answer, making it more interpretable and debuggable.\n",
        "    You can see the agent's reasoning steps, tool choices, and the information it gathered along the way.\n",
        "9.  **Tool Interaction:** ReAct heavily relies on the agent's ability to correctly choose and use available tools based on its thoughts.\n",
        "    The quality of tool descriptions is vital for the LLM to make appropriate action choices.\n",
        "10. **Potential for Loops or Errors:** While powerful, ReAct agents can sometimes get stuck in loops or make incorrect tool choices if not carefully designed or prompted.\n",
        "    Mechanisms like maximum iteration limits or more sophisticated error handling are often needed.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. AgentExecutor and ToolExecutor\n",
        "\n",
        "The `AgentExecutor` is the runtime environment in LangChain that actually runs the agent. It's the engine that takes an initialized agent (which includes the LLM and the ReAct-style prompt), a set of tools, and a user query, then orchestrates the Thought-Action-Observation loop. The `AgentExecutor` is responsible for parsing the LLM's output to distinguish between thoughts, actions (tool invocations), and final answers. When an action is identified, the `AgentExecutor` is responsible for actually calling the specified tool with the given input and then feeding its output back to the agent as an observation for the next reasoning step.\n",
        "\n",
        "While `ToolExecutor` isn't as explicitly user-facing as `AgentExecutor` in many common LangChain agent setups (the `AgentExecutor` often handles tool execution directly or via an internal mechanism), the concept of \"tool execution\" is central. Effectively, `AgentExecutor` manages this. It ensures that when the agent decides to use a tool (e.g., \"Search Tool\" with query \"current weather\"), the correct tool's function is invoked with the right parameters. It's the `AgentExecutor` that keeps the cycle going, handling things like maximum iterations, error recovery (to some extent), and returning intermediate steps if configured, until a final answer is produced or a stopping condition is met. Think of the `AgentExecutor` as the conductor of an orchestra, ensuring each musician (tool) plays its part at the right time as directed by the composer (the LLM's reasoning).\n",
        "\n",
        "**Detailed Notes: AgentExecutor and Tool Execution**\n",
        "\n",
        "1.  **`AgentExecutor`: The Runtime Engine:** This is the primary class in LangChain responsible for running an agent. It orchestrates the interaction between the LLM, tools, and the ReAct loop.\n",
        "    It takes an `agent` object (which encapsulates the LLM and prompt logic) and a list of `tools`.\n",
        "2.  **Orchestrating the ReAct Loop:** The `AgentExecutor` implements the iterative Thought-Action-Observation cycle central to ReAct agents.\n",
        "    It calls the agent to get the next action or final answer, executes tools, and feeds results back.\n",
        "3.  **Tool Invocation Management:** When the agent decides to use a tool, the `AgentExecutor` identifies the specified tool from its list and executes it with the provided input.\n",
        "    It essentially says, \"The LLM wants to use 'SearchTool' with 'What is LangChain?'. Okay, SearchTool, run with this input.\"\n",
        "4.  **Parsing LLM Output:** A crucial role of the `AgentExecutor` is to parse the raw output from the LLM to determine if it's a thought, an action (tool name and input), or a final answer.\n",
        "    This parsing relies on the specific format defined by the agent's prompt (e.g., looking for keywords like \"Action:\", \"Action Input:\").\n",
        "5.  **Input and Output Handling:** The `AgentExecutor` takes the user's initial query as input and returns the agent's final response, along with optional intermediate steps.\n",
        "    This provides a clean interface for interacting with the complex agent machinery.\n",
        "6.  **Stopping Conditions:** The `AgentExecutor` manages stopping conditions, such as when the agent produces a \"Final Answer\" or a maximum number of iterations/tool uses is reached.\n",
        "    This prevents agents from running indefinitely or getting stuck in unproductive loops.\n",
        "7.  **Error Handling and Retries:** It can be configured with error handling logic, deciding what to do if a tool fails or the LLM produces unparseable output.\n",
        "    For example, it might feed an error message back to the agent as an observation so it can try a different approach.\n",
        "8.  **Callback System Integration:** `AgentExecutor` supports LangChain's callback system, allowing for logging, tracing, and monitoring of the agent's execution steps.\n",
        "    This is invaluable for debugging and understanding the agent's behavior (e.g., using LangSmith).\n",
        "9.  **Return Intermediate Steps:** An option in `AgentExecutor` (`return_intermediate_steps=True`) allows you to get back the full sequence of thought-action-observation tuples.\n",
        "    This is extremely useful for debugging, understanding the agent's reasoning path, and transparency.\n",
        "10. **ToolExecutor (Conceptual):** While not always a distinct, separate class that users directly interact with in all agent types, the *functionality* of executing a chosen tool based on the agent's decision is handled by the `AgentExecutor`.\n",
        "    It looks up the tool by name and calls its `run` (or `_run`/`_arun`) method with the input derived from the LLM's output."
      ],
      "metadata": {
        "id": "FggbtpyJVpII"
      }
    }
  ]
}